{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 (1 point): Dummies on Month and Week-of-Month\n",
    "\n",
    "Find the CORRELATION VALUE of the most correlated dummy <month-week_of_month> with the binary outcome variable (\" is_positive_growth_5d_future\")?\n",
    "\n",
    "\n",
    "You saw in the correlation analysis and modeling that September and October may be important seasonal months. In this task, we'll go futher and try to generate dummies for Month and Week-of-month (starting from 1). For example, the first week of October should be coded similar to this: 'October_w1'. Once you've generated the new set of variables, find the most correlated (in absolute value) one with \"is_positive_growth_5d_future\" and round it to 3 digits after the comma.\n",
    "\n",
    "\n",
    "Suggested path to a solution:\n",
    "\n",
    "\n",
    "[Source] Use this formula to get the week of month for the datetime variable d: (d.day-1)//7+1\n",
    "\n",
    "\n",
    "Define a new string variable for all month-week_of_month combinations. Append it to the CATEGORICAL features set. You should have 5 variables treated as CATEGORICAL now: 'Month', 'Weekday', 'Ticker', 'ticker_type', 'month_wom'.\n",
    "\n",
    "\n",
    "Use pandas.get_dummies() to generate dummies.\n",
    "\n",
    "\n",
    "Use pandas.DataFrame.corr() function (also used in [Code Snippet 1]) to get correlations with \"is_positive_growth_5d_future\", filter out only variables representing the new dummy set, and sort it by absolute values (you can define a new column \"abs_corr\" in the dataframe with correlations), and find the highest value (among new dummies set).\n",
    "\n",
    "NOTE: new dummies will be used as features in the next tasks, please leave them in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the sample data\n",
    "df_full = pd.read_parquet(\"./stocks_df_combined_2024_05_07.parquet.brotli\", )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n3/qnzrd2254zxfjlr0q6_j679m0000gn/T/ipykernel_1841/1103908479.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  df_full['ln_volume'] = df_full.Volume.apply(lambda x: np.log(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical patterns count = 61, examples = ['cdl2crows', 'cdl3blackrows', 'cdl3inside', 'cdl3linestrike', 'cdl3outside']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 182675 entries, 3490 to 5426\n",
      "Columns: 203 entries, Open to ln_volume\n",
      "dtypes: datetime64[ns](3), float64(129), int32(64), int64(5), object(2)\n",
      "memory usage: 239.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 182675 entries, 3490 to 5426\n",
      "Columns: 184 entries, growth_1d to DGS10\n",
      "dtypes: float64(121), int32(62), int64(1)\n",
      "memory usage: 214.6 MB\n"
     ]
    }
   ],
   "source": [
    "# growth indicators (but not future growth)\n",
    "GROWTH = [g for g in df_full.keys() if (g.find('growth_')==0)&(g.find('future')<0)]\n",
    "\n",
    "# leaving only Volume ==> generate ln(Volume)\n",
    "OHLCV = ['Open','High','Low','Close','Adj Close_x','Volume']\n",
    "CATEGORICAL = ['Month', 'Weekday', 'Ticker', 'ticker_type']\n",
    "TO_PREDICT = [g for g in df_full.keys() if (g.find('future')>=0)]\n",
    "# let's define on more custom numerical features\n",
    "df_full['ln_volume'] = df_full.Volume.apply(lambda x: np.log(x))\n",
    "# manually defined features\n",
    "CUSTOM_NUMERICAL = ['SMA10', 'SMA20', 'growing_moving_average', 'high_minus_low_relative','volatility', 'ln_volume']\n",
    "\n",
    "# All Supported Ta-lib indicators: https://github.com/TA-Lib/ta-lib-python/blob/master/docs/funcs.md\n",
    "TECHNICAL_INDICATORS = ['adx', 'adxr', 'apo', 'aroon_1','aroon_2', 'aroonosc',\n",
    " 'bop', 'cci', 'cmo','dx', 'macd', 'macdsignal', 'macdhist', 'macd_ext',\n",
    " 'macdsignal_ext', 'macdhist_ext', 'macd_fix', 'macdsignal_fix',\n",
    " 'macdhist_fix', 'mfi', 'minus_di', 'mom', 'plus_di', 'dm', 'ppo',\n",
    " 'roc', 'rocp', 'rocr', 'rocr100', 'rsi', 'slowk', 'slowd', 'fastk',\n",
    " 'fastd', 'fastk_rsi', 'fastd_rsi', 'trix', 'ultosc', 'willr',\n",
    " 'ad', 'adosc', 'obv', 'atr', 'natr', 'ht_dcperiod', 'ht_dcphase',\n",
    " 'ht_phasor_inphase', 'ht_phasor_quadrature', 'ht_sine_sine', 'ht_sine_leadsine',\n",
    " 'ht_trendmod', 'avgprice', 'medprice', 'typprice', 'wclprice']\n",
    "\n",
    "TECHNICAL_PATTERNS = [g for g in df_full.keys() if g.find('cdl')>=0]\n",
    "\n",
    "print(f'Technical patterns count = {len(TECHNICAL_PATTERNS)}, examples = {TECHNICAL_PATTERNS[0:5]}')\n",
    "\n",
    "MACRO = ['gdppot_us_yoy', 'gdppot_us_qoq', 'cpi_core_yoy', 'cpi_core_mom', 'FEDFUNDS',\n",
    " 'DGS1', 'DGS5', 'DGS10']\n",
    "\n",
    "NUMERICAL = GROWTH + TECHNICAL_INDICATORS + TECHNICAL_PATTERNS + CUSTOM_NUMERICAL + MACRO\n",
    "\n",
    "# tickers, min-max date, count of daily observations\n",
    "df_full.groupby(['Ticker'])['Date'].agg(['min','max','count'])\n",
    "\n",
    "# truncated df_full with 25 years of data (and defined growth variables)\n",
    "df = df_full[df_full.Date>='2000-01-01']\n",
    "df.info()\n",
    "\n",
    "# let look at the features count and size:\n",
    "df[NUMERICAL].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df.loc[:,'Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n3/qnzrd2254zxfjlr0q6_j679m0000gn/T/ipykernel_1841/3020723848.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Month'] = df['Date'].dt.month_name()\n",
      "/var/folders/n3/qnzrd2254zxfjlr0q6_j679m0000gn/T/ipykernel_1841/3020723848.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Week_of_Month'] = (df['Date'].dt.day - 1) // 7 + 1\n"
     ]
    }
   ],
   "source": [
    "# Create 'Month' and 'Week_of_Month' columns\n",
    "df['Month'] = df['Date'].dt.month_name()\n",
    "df['Week_of_Month'] = (df['Date'].dt.day - 1) // 7 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n3/qnzrd2254zxfjlr0q6_j679m0000gn/T/ipykernel_1841/3185243579.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['month_wom'] = df['Month'] + '_w' + df['Week_of_Month'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Combine 'Month' and 'Week_of_Month' into a single column\n",
    "df['month_wom'] = df['Month'] + '_w' + df['Week_of_Month'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add 'month_wom' to your list of categorical features\n",
    "CATEGORICAL = ['Month', 'Weekday', 'Ticker', 'ticker_type', 'month_wom']\n",
    "\n",
    "TO_DROP = ['Year','Date','index_x', 'index_y', 'index', 'Quarter','Adj Close_y'] + CATEGORICAL + OHLCV\n",
    "OTHER = [k for k in df_full.keys() if k not in OHLCV + CATEGORICAL + NUMERICAL + TO_DROP]\n",
    "\n",
    "# Generate dummy variables for the categorical features\n",
    "dummies = pd.get_dummies(df[CATEGORICAL],dtype='int32')\n",
    "DUMMIES = dummies.keys().to_list()\n",
    "DUMMIES\n",
    "# Join dummies back to the original dataframe\n",
    "df_dummies = pd.concat([df, dummies], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations with 'is_positive_growth_5d_future'\n",
    "correlations_df = df_dummies[DUMMIES+['is_positive_growth_5d_future']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_5d_corr = correlations_df['is_positive_growth_5d_future'].drop('is_positive_growth_5d_future')\n",
    "growth_5d_corr_max = growth_5d_corr.abs().max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CORRELATION VALUE of the most correlated dummy <month-week_of_month> with the binary outcome variable:0.035\n"
     ]
    }
   ],
   "source": [
    "# find the max value of growth_5d_corr\n",
    "print(f'The CORRELATION VALUE of the most correlated dummy <month-week_of_month> with the binary outcome variable:{growth_5d_corr_max:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 (2 points): Define new \"hand\" rules on macro and technical indicators variables\n",
    "\n",
    "\n",
    "What is the precision score for the best of the NEW variables (pred3 or pred4)\n",
    "\n",
    "\n",
    "Let's utilize the knowledge from the visualised tree (clf10) (Code Snippet 5: 1.4.4 Visualisation). You're asked to define two new 'hand' rules (leading to 'positive' subtrees):\n",
    "\n",
    "\n",
    "pred3_manual_gdp_fastd: (gdppot_us_yoy <= 0.027) & (fastd >= 0.251)\n",
    "pred4_manual_gdp_wti_oil: (gdppot_us_yoy >= 0.027) & (growth_wti_oil_30d <= 1.005)\n",
    "Extend the Code Snippet 3 (Manual \"hand rule\" predictions): Calculate and add them to the dataframe. You should notice that one of the predictions doesn't have any positive predictions on TEST dataset. Please debug that: check in the 'new_df' and the original dataset/data generation process that we didn't make any mistakes at the data transformations step; explain why this can happen even if there are no mistakes at the data transformation step.\n",
    "\n",
    "As a result, write down the precision score for the remaining predictor (round to three decimal points). E.g. if you have 0.57897, your answer should be 0.579.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_split(df, min_date, max_date, train_prop=0.7, val_prop=0.15, test_prop=0.15):\n",
    "    \"\"\"\n",
    "    Splits a DataFrame into three buckets based on the temporal order of the 'Date' column.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame to split.\n",
    "        min_date (str or Timestamp): Minimum date in the DataFrame.\n",
    "        max_date (str or Timestamp): Maximum date in the DataFrame.\n",
    "        train_prop (float): Proportion of data for training set (default: 0.6).\n",
    "        val_prop (float): Proportion of data for validation set (default: 0.2).\n",
    "        test_prop (float): Proportion of data for test set (default: 0.2).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The input DataFrame with a new column 'split' indicating the split for each row.\n",
    "    \"\"\"\n",
    "    # Define the date intervals\n",
    "    train_end = min_date + pd.Timedelta(days=(max_date - min_date).days * train_prop)\n",
    "    val_end = train_end + pd.Timedelta(days=(max_date - min_date).days * val_prop)\n",
    "\n",
    "    # Assign split labels based on date ranges\n",
    "    split_labels = []\n",
    "    for date in df['Date']:\n",
    "        if date <= train_end:\n",
    "            split_labels.append('train')\n",
    "        elif date <= val_end:\n",
    "            split_labels.append('validation')\n",
    "        else:\n",
    "            split_labels.append('test')\n",
    "\n",
    "    # Add 'split' column to the DataFrame\n",
    "    df['split'] = split_labels\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date_df = df_dummies.Date.min()\n",
    "max_date_df = df_dummies.Date.max()\n",
    "\n",
    "df_dummies = temporal_split(df_dummies,\n",
    "                                 min_date = min_date_df,\n",
    "                                 max_date = max_date_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train         0.675834\n",
       "test          0.163290\n",
       "validation    0.160876\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies['split'].value_counts()/len(df_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the \"segmentation\" problem (warning message on df performance after many joins and data transformations)\n",
    "new_df = df_dummies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>29664.0</td>\n",
       "      <td>1.005015</td>\n",
       "      <td>0.040835</td>\n",
       "      <td>0.690219</td>\n",
       "      <td>0.981994</td>\n",
       "      <td>1.004731</td>\n",
       "      <td>1.027028</td>\n",
       "      <td>1.393477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>123458.0</td>\n",
       "      <td>1.003965</td>\n",
       "      <td>0.053826</td>\n",
       "      <td>0.412383</td>\n",
       "      <td>0.978474</td>\n",
       "      <td>1.003197</td>\n",
       "      <td>1.028354</td>\n",
       "      <td>3.018887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>29388.0</td>\n",
       "      <td>1.004417</td>\n",
       "      <td>0.040642</td>\n",
       "      <td>0.668581</td>\n",
       "      <td>0.985343</td>\n",
       "      <td>1.005120</td>\n",
       "      <td>1.023999</td>\n",
       "      <td>1.459217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count      mean       std       min       25%       50%  \\\n",
       "split                                                                    \n",
       "test         29664.0  1.005015  0.040835  0.690219  0.981994  1.004731   \n",
       "train       123458.0  1.003965  0.053826  0.412383  0.978474  1.003197   \n",
       "validation   29388.0  1.004417  0.040642  0.668581  0.985343  1.005120   \n",
       "\n",
       "                 75%       max  \n",
       "split                           \n",
       "test        1.027028  1.393477  \n",
       "train       1.028354  3.018887  \n",
       "validation  1.023999  1.459217  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.groupby(by='split')['growth_future_5d'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>month_wom_October_w2</th>\n",
       "      <th>month_wom_October_w3</th>\n",
       "      <th>month_wom_October_w4</th>\n",
       "      <th>month_wom_October_w5</th>\n",
       "      <th>month_wom_September_w1</th>\n",
       "      <th>month_wom_September_w2</th>\n",
       "      <th>month_wom_September_w3</th>\n",
       "      <th>month_wom_September_w4</th>\n",
       "      <th>month_wom_September_w5</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>58.6875</td>\n",
       "      <td>59.3125</td>\n",
       "      <td>56.0</td>\n",
       "      <td>58.28125</td>\n",
       "      <td>36.065567</td>\n",
       "      <td>53228400.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2000</td>\n",
       "      <td>January</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open     High   Low     Close  Adj Close_x      Volume Ticker  Year  \\\n",
       "3490  58.6875  59.3125  56.0  58.28125    36.065567  53228400.0   MSFT  2000   \n",
       "\n",
       "        Month  Weekday  ... month_wom_October_w2  month_wom_October_w3  \\\n",
       "3490  January        0  ...                    0                     0   \n",
       "\n",
       "      month_wom_October_w4  month_wom_October_w5  month_wom_September_w1  \\\n",
       "3490                     0                     0                       0   \n",
       "\n",
       "      month_wom_September_w2  month_wom_September_w3  month_wom_September_w4  \\\n",
       "3490                       0                       0                       0   \n",
       "\n",
       "      month_wom_September_w5  split  \n",
       "3490                       0  train  \n",
       "\n",
       "[1 rows x 315 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check one record: it has abs. values, text, and numbers\n",
    "new_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>29829</td>\n",
       "      <td>2020-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>123458</td>\n",
       "      <td>2000-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>2020-09-11</td>\n",
       "      <td>29388</td>\n",
       "      <td>2017-01-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  max   count        min\n",
       "split                                   \n",
       "test       2024-05-07   29829 2020-09-14\n",
       "train      2017-01-16  123458 2000-01-03\n",
       "validation 2020-09-11   29388 2017-01-17"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time split on train/validation/test: FIXED dates of split, approx. 70%, 15%, 15% split\n",
    "new_df.groupby(['split'])['Date'].agg({'min','max','count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>growth_future_5d</th>\n",
       "      <th>is_positive_growth_5d_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>0.963003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      growth_future_5d  is_positive_growth_5d_future\n",
       "3490          0.963003                             0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what we try to predict\n",
    "new_df[TO_PREDICT].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>growth_1d</th>\n",
       "      <th>growth_3d</th>\n",
       "      <th>growth_7d</th>\n",
       "      <th>growth_30d</th>\n",
       "      <th>growth_90d</th>\n",
       "      <th>growth_365d</th>\n",
       "      <th>growth_dax_1d</th>\n",
       "      <th>growth_dax_3d</th>\n",
       "      <th>growth_dax_7d</th>\n",
       "      <th>growth_dax_30d</th>\n",
       "      <th>...</th>\n",
       "      <th>month_wom_October_w1</th>\n",
       "      <th>month_wom_October_w2</th>\n",
       "      <th>month_wom_October_w3</th>\n",
       "      <th>month_wom_October_w4</th>\n",
       "      <th>month_wom_October_w5</th>\n",
       "      <th>month_wom_September_w1</th>\n",
       "      <th>month_wom_September_w2</th>\n",
       "      <th>month_wom_September_w3</th>\n",
       "      <th>month_wom_September_w4</th>\n",
       "      <th>month_wom_September_w5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>0.998394</td>\n",
       "      <td>0.988341</td>\n",
       "      <td>0.991494</td>\n",
       "      <td>1.372333</td>\n",
       "      <td>1.222951</td>\n",
       "      <td>2.063053</td>\n",
       "      <td>0.970196</td>\n",
       "      <td>0.983855</td>\n",
       "      <td>1.051736</td>\n",
       "      <td>1.134572</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      growth_1d  growth_3d  growth_7d  growth_30d  growth_90d  growth_365d  \\\n",
       "3490   0.998394   0.988341   0.991494    1.372333    1.222951     2.063053   \n",
       "\n",
       "      growth_dax_1d  growth_dax_3d  growth_dax_7d  growth_dax_30d  ...  \\\n",
       "3490       0.970196       0.983855       1.051736        1.134572  ...   \n",
       "\n",
       "      month_wom_October_w1  month_wom_October_w2  month_wom_October_w3  \\\n",
       "3490                     0                     0                     0   \n",
       "\n",
       "      month_wom_October_w4  month_wom_October_w5  month_wom_September_w1  \\\n",
       "3490                     0                     0                       0   \n",
       "\n",
       "      month_wom_September_w2  month_wom_September_w3  month_wom_September_w4  \\\n",
       "3490                       0                       0                       0   \n",
       "\n",
       "      month_wom_September_w5  \n",
       "3490                       0  \n",
       "\n",
       "[1 rows x 294 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to be used as features\n",
    "new_df[NUMERICAL+DUMMIES].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate manual predictions\n",
    "# Let's label all prediction features with prefix \"pred\"\n",
    "new_df['pred0_manual_cci'] = (new_df.cci>200).astype(int)\n",
    "new_df['pred1_manual_prev_g1'] = (new_df.growth_1d>1).astype(int)\n",
    "new_df['pred2_manual_prev_g1_and_snp'] = ((new_df['growth_1d'] > 1) & (new_df['growth_snp500_1d'] > 1)).astype(int)\n",
    "# Define the new 'hand' rules\n",
    "new_df['pred3_manual_gdp_fastd'] = (df['gdppot_us_yoy'] <= 0.027) & (df['fastd'] >= 0.251).astype(int)\n",
    "new_df['pred4_manual_gdp_wti_oil'] = (df['gdppot_us_yoy'] >= 0.027) & (df['growth_wti_oil_30d'] <= 1.005).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate precision scores\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Assuming 'is_positive_growth_5d_future' is the actual target variable\n",
    "test_idx = new_df.split.isin(['test'])\n",
    "precision_pred3 = precision_score(new_df.loc[test_idx,'is_positive_growth_5d_future'], new_df.loc[test_idx,'pred3_manual_gdp_fastd'],zero_division=0)\n",
    "precision_pred4 = precision_score(new_df.loc[test_idx,'is_positive_growth_5d_future'], new_df.loc[test_idx,'pred4_manual_gdp_wti_oil'],zero_division=0)\n",
    "\n",
    "# Select the best precision score\n",
    "best_precision = max(precision_pred3, precision_pred4)\n",
    "best_precision_rounded = round(best_precision, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision score for the remaining predictor is 0.555\n"
     ]
    }
   ],
   "source": [
    "print(f'The precision score for the remaining predictor is {best_precision_rounded:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3 (1 point): Unique correct predictions from a 10-levels deep decision tree classifier (pred5_clf_10)\n",
    "\n",
    "What is the total number of records in the TEST dataset when the new prediction pred5_clf_10 is better than all 'hand' rules (pred0..pred4)?\n",
    "\n",
    "\n",
    "NOTE: please include random_state=42 to Decision Tree Classifier init function (line clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)) to ensure everyone gets the same results.\n",
    "\n",
    "\n",
    "Suggested solution: \n",
    "\n",
    "Rewrite the '1.4.3 Inference for a decision tree' piece for the Decision Tree Classifier with max_depth=10 (clf_10), so that you fit the model on TRAIN+VALIDATION sets (unchanged from the lecture), but predict on the whole set X_all (to be able to define a new column 'pred5_clf_10' in the dataframe new_df). Here is the link with explanation. It will solve the problem in 1.4.5 when predictions were made only for Test dataset and couldn't be easily joined with the full dataset.\n",
    "\n",
    "\n",
    "Once you have it, define a new column 'only_pred5_is_correct' similar to 'hand' prediction rules with several conditions: is_positive_growth_5d_future AND is_correct_pred5 should be equal 1, while all other predictions is_correct_pred0..is_correct_pred4 should be equal to 0.\n",
    "\n",
    "\n",
    "Convert 'only_pred5_is_correct' column from bool to int, and find how many times it is equal to 1 in the TEST set. Write down this as an answer.\n",
    "\n",
    "\n",
    "ADVANCED: define a function that can be applied to the whole row (examples) and can find whether some prediction 'predX' (where X is one of the predictions) is uniquely correct. It should work even if there are 100 predictions available, so that you don't define manually the condition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pred0_manual_cci',\n",
       " 'pred1_manual_prev_g1',\n",
       " 'pred2_manual_prev_g1_and_snp',\n",
       " 'pred3_manual_gdp_fastd',\n",
       " 'pred4_manual_gdp_wti_oil']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDITIONS = [k for k in new_df.keys() if  k.startswith('pred')]\n",
    "PREDITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = NUMERICAL+DUMMIES\n",
    "to_predict = 'is_positive_growth_5d_future'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "new_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to prepae dataset for DecisionTreeClassifier\n",
    "# Rewrite the '1.4.3 Inference for a decision tree' piece for the Decision Tree Classifier with max_depth=10 (clf_10), \n",
    "# so that you fit the model on TRAIN+VALIDATION sets (unchanged from the lecture), \n",
    "# but predict on the whole set X_all (to be able to define a new column 'pred5_clf_10' in the dataframe new_df).\n",
    "# Here is the link with explanation. It will solve the problem in 1.4.5 when predictions were made only for Test dataset \n",
    "# and couldn't be easily joined with the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO 3: Implement the unique correct predictions using a 10-levels deep Decision Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Fit the model on TRAIN+VALIDATION sets\n",
    "train_df = new_df[new_df.split.isin(['train','validation'])]\n",
    "test_df = new_df[new_df.split.isin(['test'])]\n",
    "X_train = train_df[features_list]\n",
    "X_test = test_df[features_list]\n",
    "y_train = train_df[to_predict]\n",
    "y_test = test_df[to_predict]\n",
    "# Initialize the Decision Tree Classifier with max_depth=10 and random_state=42\n",
    "clf_10 = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "clf_10.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on the whole set X_all\n",
    "X_all = new_df[features_list]\n",
    "new_df['pred5_clf_10'] = clf_10.predict(X_all)\n",
    "\n",
    "# # Define the new column 'only_pred5_is_correct'\n",
    "new_df['is_correct_pred5'] = new_df['pred5_clf_10'] == new_df['is_positive_growth_5d_future']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['is_correct_pred0'] = new_df['pred0_manual_cci'] == new_df['is_positive_growth_5d_future']\n",
    "new_df['is_correct_pred1'] = new_df['pred1_manual_prev_g1'] == new_df['is_positive_growth_5d_future']\n",
    "new_df['is_correct_pred2'] = new_df['pred2_manual_prev_g1_and_snp'] == new_df['is_positive_growth_5d_future']\n",
    "new_df['is_correct_pred3'] = new_df['pred3_manual_gdp_fastd'] == new_df['is_positive_growth_5d_future']\n",
    "new_df['is_correct_pred4'] = new_df['pred4_manual_gdp_wti_oil'] == new_df['is_positive_growth_5d_future']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Conditions for only_pred5_is_correct\n",
    "new_df['only_pred5_is_correct'] = (\n",
    "    new_df['is_correct_pred5'] &\n",
    "    ~new_df['is_correct_pred0'] &\n",
    "    ~new_df['is_correct_pred1'] &\n",
    "    ~new_df['is_correct_pred2'] &\n",
    "    ~new_df['is_correct_pred3'] &\n",
    "    ~new_df['is_correct_pred4']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of times \"only_pred5_is_correct\" is equal to 1 in the TEST set is 1\n"
     ]
    }
   ],
   "source": [
    "# Find how many times 'only_pred5_is_correct' is equal to 1 in the TEST set\n",
    "test_only_pred5_correct_count = new_df.loc[test_idx, 'only_pred5_is_correct'].sum()\n",
    "\n",
    "print(f'The number of times \"only_pred5_is_correct\" is equal to 1 in the TEST set is {test_only_pred5_correct_count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: (2 points) Hyperparameter tuning for a Decision Tree\n",
    "What is the optimal tree depth (from 1 to 20) for a DecisionTreeClassifier?\n",
    "\n",
    "Modify the section 1.4 [Code Snippet 4]\n",
    "\n",
    "\n",
    "Re-define the train set X_train (using the condition split=='train'), create a validation set X_valid (using the condition split=='validation'), and leave the test set X_test unchanged.\n",
    "\n",
    "Apply the same data transformation rules (replace +-inf with NaN and then replace all NaNs with 0).\n",
    "\n",
    "Iterate in a loop for max_depth between 1 and 20:\n",
    "Train the DecisionTreeClassifier (clf) with max_depth=k on a train set.\n",
    "\n",
    "Find the precision and accuracy scores on the validation set.\n",
    "\n",
    "Select the best_max_depth based on precision only and write it down as an answer.\n",
    "\n",
    "\n",
    "(Advanced: Read about scikit-learn Decision Trees. Do you see the 'saturation' of precision/accuracy when max_depth is increasing, or there is a tendency of overfitting?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define the train set X_train (using the condition split=='train'), create a validation set X_valid (using the condition split=='validation'), and leave the test set X_test unchanged.\n",
    "# Re-define the train set X_train\n",
    "X_train = new_df[new_df['split'] == 'train'][features_list]\n",
    "y_train = new_df[new_df['split'] == 'train'][to_predict]\n",
    "\n",
    "# Create a validation set X_valid\n",
    "X_valid = new_df[new_df['split'] == 'validation'][features_list]\n",
    "y_valid = new_df[new_df['split'] == 'validation'][to_predict]\n",
    "\n",
    "# Leave the test set X_test unchanged\n",
    "X_test = new_df[new_df['split'] == 'test'][features_list]\n",
    "y_test = new_df[new_df['split'] == 'test'][to_predict]\n",
    "\n",
    "X_all = new_df[features_list]\n",
    "y_all = new_df[to_predict]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best max_depth is 15 and the corresponding highest precision score is 0.569\n"
     ]
    }
   ],
   "source": [
    "# TODO 4: Hyperparameter tuning for a Decision Tree to find the optimal max_depth\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Initialize variables to track the best max_depth and highest precision score\n",
    "best_max_depth = 0\n",
    "highest_precision = 0\n",
    "\n",
    "# Iterate through max_depth values from 1 to 20\n",
    "for max_depth in range(1, 21):\n",
    "    # Initialize the Decision Tree Classifier with the current max_depth and random_state=42\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "    \n",
    "    # Fit the model on TRAIN+VALIDATION sets\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the TEST set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate the precision score on the TEST set\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    \n",
    "    # Update the best_max_depth and highest_precision if current precision is higher\n",
    "    if precision > highest_precision:\n",
    "        highest_precision = precision\n",
    "        best_max_depth = max_depth\n",
    "\n",
    "# Output the best_max_depth and corresponding highest precision score\n",
    "print(f'The best max_depth is {best_max_depth} and the corresponding highest precision score is {highest_precision:.3f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7185504013861879"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model with the best_max_depth on the entire dataset (TRAIN+VALIDATION+TEST)\n",
    "clf_best = DecisionTreeClassifier(max_depth=best_max_depth, random_state=42)\n",
    "clf_best.fit(X_all, y_all)\n",
    "\n",
    "# Make predictions on all records and add the new prediction pred6_clf_best to the dataframe\n",
    "new_df['pred6_clf_best'] = clf_best.predict(X_all)\n",
    "\n",
    "# Compare the precision score of the tuned decision tree with previous predictions\n",
    "precision_best = precision_score(y_all, new_df['pred6_clf_best'])\n",
    "\n",
    "# Output the precision score of the tuned decision tree\n",
    "precision_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[EXPLORATORY] Question 5: What data is missing?\n",
    "[探索性]問題 5：缺少哪些數據？\n",
    "Now that you have some insights from the correlation analysis and the Decision Trees regarding the most influential variables, suggest new indicators you would like to include in the dataset and explain why.\n",
    "\n",
    "You can also propose something entirely different based on your intuition, but it should be relevant to the shared dataset of the largest Indian, EU, and US stocks. If you choose this approach, please specify the data source as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitting the solutions 提交解決方案 \n",
    "[NOT READY YET] Form for submitting: https://courses.datatalks.club/sma-zoomcamp-2024/homework/hw03\n",
    "[還沒準備好]提交表格：https://courses.datatalks.club/sma-zoomcamp-2024/homework/hw03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaderboard 排行榜 \n",
    "Leaderboard link: https://courses.datatalks.club/sma-zoomcamp-2024/leaderboard\n",
    "排行榜連結： https://courses.datatalks.club/sma-zoomcamp-2024/leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
